{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zero-Shot Classification and Few-Shot Fine-Tuning for News Articles\"\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This tutorial demonstrates a modern approach to text classification, combining the power of Large Language Models (LLMs) for zero-shot labeling with efficient fine-tuning using SetFit, and leveraging Argilla for human-in-the-loop validation and data management. We will classify news articles into categories: World, Sports, Business, and Sci/Tech.\n",
        "\n",
        "**Workflow Overview:**\n",
        "\n",
        "1.  **Zero-Shot Classification with LLM**: We'll use an LLM via the Together API to automatically label a sample of news articles without any prior training examples.\n",
        "2.  **Human Review and Correction with Argilla**: We'll use Argilla to review and correct the LLM-generated labels, ensuring data quality and creating a gold-standard dataset.\n",
        "3.  **Few-Shot Fine-tuning with SetFit**: We'll fine-tune a Sentence-transformers model using SetFit on the human-validated data from Argilla. SetFit is designed for efficient few-shot learning.\n",
        "4.  **Evaluation and Comparison**: We'll evaluate the performance of the SetFit model and compare it to a traditional Logistic Regression model trained on a larger dataset.\n",
        "\n",
        "Let's begin by installing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: install-libraries\n",
        "#| echo: false\n",
        "!pip install openai datasets sentence-transformers argilla setfit -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setting up the Environment and API Keys\n",
        "\n",
        "First, we import the required libraries and initialize Argilla and the OpenAI client (for Together API). Ensure you have an Argilla account and a Together API key. You'll need to set your Together API key as a Colab userdata secret named `TOGETHER_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: setup-environment\n",
        "import json\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from datasets import load_dataset, Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import argilla as rg\n",
        "from setfit import SetFitModel, Trainer, TrainingArguments\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# API key for Together API (use your own API key)\n",
        "from google.colab import userdata\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "# Initialize Argilla client with the new API structure\n",
        "client = rg.Argilla(\n",
        "    api_url=\"https://<your_space>.hf.space\", # Replace with your Argilla API URL\n",
        "    api_key=\"xxxxx-xxx\", # Replace with your Argilla API Key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Zero-Shot Classification with LLM\n",
        "\n",
        "In this section, we define the categories for news classification and set up an LLM-based classifier using the Together API. We use a system prompt to guide the LLM's classification task and ensure JSON formatted output for easy parsing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: define-categories-prompt\n",
        "# Define news categories for classification\n",
        "categories = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "# Define system prompt for the LLM - instructs the LLM for zero-shot classification\n",
        "system_prompt = \"\"\"\n",
        "You are a sophisticated classification engine tasked with categorizing news articles.\n",
        "Your primary function is to evaluate the core message of each article and assign it to one of the following categories:\n",
        "\"World\" for global news covering politics and similar topics,\n",
        "\"Sports\" for news related to sports,\n",
        "\"Business\" for articles on business, economics, or finance,\n",
        "and \"Sci/Tech\" for content focused on technology and science.\n",
        "\n",
        "Upon analyzing a text input, you will provide an explanation for the category chosen.\n",
        "Your output will adhere strictly to the JSON format, specifically:\n",
        "{\"prediction\":\"your selected prediction\", \"explanation\":\"your explanation\"}.\n",
        "It is imperative that your output is VALID JSON and contains no other elements.\n",
        "\"\"\"\n",
        "\n",
        "# Create an OpenAI-compatible client using Together API\n",
        "llm_client = OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=TOGETHER_API_KEY)\n",
        "\n",
        "# Function to classify text using the LLM\n",
        "def classify(text):\n",
        "    completion = llm_client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",  # Using an open-source LLM - maybe\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": f'Classify following text: {text}'}\n",
        "        ],\n",
        "        temperature=0.2,  # Lower temperature for more consistent outputs\n",
        "    )\n",
        "    json_response = completion.choices[0].message.content.strip()\n",
        "    try:\n",
        "        prediction = json.loads(json_response) # Parse JSON response\n",
        "    except:\n",
        "        # Fallback for incorrectly formatted JSON\n",
        "        return {\"prediction\": None, \"explanation\": f\"Error parsing JSON: {json_response}\"}\n",
        "    return prediction\n",
        "\n",
        "# Example news article for testing\n",
        "text_example = \"\"\"\n",
        "Stocks Rally on Lower Oil Prices. Stocks rallied in quiet trading Wednesday\n",
        "as lower oil prices brought out buyers, countering a pair of government reports\n",
        "that gave a mixed picture of the economy.\n",
        "\"\"\"\n",
        "\n",
        "# Test the classification function\n",
        "result = classify(text_example)\n",
        "print(f\"Example classification:\\nText: {text_example}\\nResult: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's apply this classification function to a sample of news articles. We load a small sample from the `ag_news_unlabelled` dataset for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: classify-sample-data\n",
        "# Load a sample of news articles for demonstration\n",
        "data_train = pd.read_parquet('https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/ag_news_unlabelled.pq')\n",
        "dataset_news = Dataset.from_pandas(data_train.sample(20).reset_index(drop=True))  # Sample 20 articles\n",
        "\n",
        "# Apply zero-shot classification to our sample\n",
        "print(\"Classifying news articles with LLM...\")\n",
        "news_with_preds = []\n",
        "for example in dataset_news:\n",
        "    result = classify(example[\"text\"])\n",
        "    news_with_preds.append({\n",
        "        \"text\": example[\"text\"],\n",
        "        \"label\": result[\"prediction\"],\n",
        "        \"explanation\": result[\"explanation\"]\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here are a few examples of the LLM's predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: display-sample-predictions\n",
        "# Display sample predictions\n",
        "print(\"\\nSample of LLM predictions:\")\n",
        "for i, item in enumerate(news_with_preds[:3]):\n",
        "    print(f\"\\nArticle {i+1}:\")\n",
        "    print(f\"Text: {item['text'][:100]}...\")\n",
        "    print(f\"Prediction: {item['label']}\")\n",
        "    print(f\"Explanation: {item['explanation']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Human Review and Data Logging to Argilla with Embeddings\n",
        "\n",
        "Now, we will use Argilla to create a dataset for human review of the LLM predictions. We also generate sentence embeddings for each news article to enable semantic search and similarity features in Argilla. We use `SentenceTransformer` to create these embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: create-argilla-dataset\n",
        "# Initialize sentence transformer model for embeddings\n",
        "print(\"\\nGenerating vector embeddings...\")\n",
        "model = SentenceTransformer(\"TaylorAI/bge-micro-v2\")  # 384-dimensional embeddings\n",
        "\n",
        "# Create a dataset in Argilla with vector settings properly included\n",
        "print(\"\\nCreating Argilla dataset...\")\n",
        "\n",
        "# Configure dataset settings with vector settings\n",
        "settings = rg.Settings(\n",
        "    guidelines=\"Classify news articles into one of the categories: World, Sports, Business, or Sci/Tech.\",\n",
        "    fields=[\n",
        "        rg.TextField(\n",
        "            name=\"text\",\n",
        "        ),\n",
        "        rg.TextField(\n",
        "            name=\"explanation\",\n",
        "            title=\"LLM Explanation\",\n",
        "        ),\n",
        "    ],\n",
        "    questions=[\n",
        "        rg.LabelQuestion(\n",
        "            name=\"label\",\n",
        "            title=\"Category\",\n",
        "            labels=categories\n",
        "        ),\n",
        "    ],\n",
        "    # Vector settings for embeddings\n",
        "    vectors=[\n",
        "        rg.VectorField(\n",
        "            name=\"sentence_embedding\",\n",
        "            title=\"Sentence Embedding\",\n",
        "            dimensions=384  # Using bge-micro embeddings which are 384-dimensional\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create dataset\n",
        "dataset_name = \"news\"\n",
        "try:\n",
        "    # Check if dataset exists\n",
        "    dataset = client.datasets.get(dataset_name)\n",
        "    print(f\"Dataset '{dataset_name}' already exists\")\n",
        "except:\n",
        "    # Create new dataset\n",
        "    dataset = rg.Dataset(\n",
        "        name=dataset_name,\n",
        "        settings=settings,\n",
        "    )\n",
        "    dataset.create()\n",
        "    print(f\"Created new dataset '{dataset_name}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We prepare the data records with sentence embeddings and log them to the Argilla dataset. The embeddings are stored as vector fields within Argilla, which can be used for advanced search and exploration within the Argilla platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: log-records-argilla\n",
        "# Prepare records with vectors using FLAT structure\n",
        "print(\"Preparing records with embeddings before logging...\")\n",
        "records_with_vectors = []\n",
        "\n",
        "for item in news_with_preds:\n",
        "    if item[\"label\"] is not None:\n",
        "        # Generate embedding for this text\n",
        "        embedding = model.encode(item[\"text\"]).tolist()\n",
        "\n",
        "        # Create record with FLAT structure (no nesting)\n",
        "        records_with_vectors.append({\n",
        "            \"text\": item[\"text\"],\n",
        "            \"explanation\": item[\"explanation\"],\n",
        "            \"label\": item[\"label\"],\n",
        "            \"sentence_embedding\": embedding  # Vector included directly\n",
        "        })\n",
        "\n",
        "# Log records WITH vectors to Argilla in a single operation\n",
        "if records_with_vectors:\n",
        "    dataset.records.log(records_with_vectors)\n",
        "    print(f\"Logged {len(records_with_vectors)} records with embeddings to Argilla\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running the above cells, you can access the Argilla UI to review and annotate the LLM predictions. Correct any misclassifications and ensure the data is of high quality. Once annotation is complete in Argilla, we can load the hand-labeled data for SetFit fine-tuning.\n",
        "\n",
        "## 4. Few-Shot Fine-tuning with SetFit\n",
        "\n",
        "Now we will fine-tune a SetFit model using the data annotated in Argilla. SetFit is efficient for few-shot learning scenarios, making it ideal for leveraging our human-validated dataset.\n",
        "\n",
        "First, we retrieve the annotated dataset from Argilla and load the AG News test dataset for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: load-annotated-data-test-data\n",
        "# Retrieve the dataset from Argilla\n",
        "retrieved_dataset = client.datasets(name=\"news\", workspace=\"argilla\")\n",
        "\n",
        "# Load the handlabelled dataset from Argilla\n",
        "train_ds = retrieved_dataset.records.to_datasets()\n",
        "\n",
        "# Load the AG News test dataset\n",
        "test_ds = load_dataset(\"ag_news\", split=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We convert the Argilla dataset to a Pandas DataFrame to process the labels and remove records without human annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: prepare-training-data\n",
        "# Convert to pandas for easier manipulation\n",
        "train_ds_df = train_ds.to_pandas()\n",
        "train_ds_df.dropna(subset=\"label.responses\", inplace=True) # Remove records without human label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect the label responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "output-fold": true
      },
      "outputs": [],
      "source": [
        "#| label: inspect-label-responses\n",
        "# Extract label responses - output folded for brevity\n",
        "train_ds_df['label.responses'].map(lambda t: t[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also check the features of the test dataset to understand its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: check-test-dataset-features\n",
        "# Check test dataset features\n",
        "test_ds.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For faster evaluation during this tutorial, we select a small subset of the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: subset-test-data\n",
        "# Select a subset of the test dataset for SetFit evaluation\n",
        "test_df_setfit = test_ds.shuffle(seed=42).select(range(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To prepare the labels for training, we create a mapping from label names to numerical indices, consistent with the AG News dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: create-label-mapping\n",
        "# Create a mapping between label names and indices\n",
        "mapping = dict(enumerate(test_ds.features['label'].names))\n",
        "mapping = {v: k for k, v in mapping.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we map the human-annotated labels from Argilla to numerical indices and convert the processed DataFrame back to a Dataset format, ready for SetFit training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: map-labels-dataset-format\n",
        "# Map label responses to label indices\n",
        "train_ds_df['label'] = train_ds_df['label.responses'].map(lambda t: mapping[t[0]])\n",
        "\n",
        "# Convert back to Dataset format\n",
        "train_ds_prepared = Dataset.from_pandas(train_ds_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load a pre-trained SetFit model and initialize the trainer with training arguments suitable for few-shot fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: load-setfit-model\n",
        "# Load a SetFit model from Hugging Face Hub\n",
        "model = SetFitModel.from_pretrained(\n",
        "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
        "    labels=['World', 'Sports', 'Business', 'Sci/Tech'] # Specify the labels for the classifier\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We configure the training arguments, initialize the SetFit Trainer, and train the model using our prepared training dataset and evaluate on the test subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: train-setfit-model\n",
        "# SetFit training configuration\n",
        "args = TrainingArguments(\n",
        "    batch_size=16,\n",
        "    num_epochs=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\", # Avoid logging to experiment trackers for simplicity in this tutorial\n",
        ")\n",
        "\n",
        "# Initialize and train the SetFit model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds_prepared,\n",
        "    eval_dataset=test_df_setfit,\n",
        "    metric=\"accuracy\", # Evaluate using accuracy\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics) # Print evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training, we predict labels on the test subset using the fine-tuned SetFit model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: predict-setfit\n",
        "# Predict using the trained SetFit model\n",
        "predicted_labels = model.predict(test_ds['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For evaluation, we create a reverse mapping to convert numerical labels back to their names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: create-reverse-mapping\n",
        "# Create reverse mapping for label evaluation\n",
        "mapping_reverse = {v: k for k, v in mapping.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we evaluate the performance of the SetFit model using a classification report, showing precision, recall, F1-score, and support for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: evaluate-setfit\n",
        "# Evaluate SetFit model performance\n",
        "print(classification_report([mapping_reverse[x] for x in test_ds['label']], predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comparison with Logistic Regression\n",
        "\n",
        "To provide a baseline comparison, we train a traditional Logistic Regression model on the full AG News training dataset. This helps to contextualize the performance of our SetFit model, especially considering SetFit is trained on a much smaller, human-validated dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: train-logistic-regression\n",
        "# Load AG News dataset for logistic regression comparison\n",
        "dataset = load_dataset(\"ag_news\", split={'train': 'train', 'test': 'test'})\n",
        "\n",
        "# Training and test sets\n",
        "train_texts = dataset['train']['text']\n",
        "train_labels = dataset['train']['label']\n",
        "test_texts = dataset['test']['text']\n",
        "test_labels = dataset['test']['label']\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "model_lg = make_pipeline(TfidfVectorizer(stop_words='english'), LogisticRegression(max_iter=1000))\n",
        "model_lg.fit(train_texts, train_labels)\n",
        "\n",
        "# Predict and evaluate the logistic regression model\n",
        "predicted_labels = model_lg.predict(test_texts)\n",
        "print(classification_report(test_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This tutorial demonstrated a complete workflow for text classification, starting from zero-shot labeling with LLMs, incorporating human feedback with Argilla, and efficiently fine-tuning a model with SetFit. We showed how to integrate modern LLM techniques with human-in-the-loop processes to create high-quality labeled datasets and achieve good classification performance even with limited annotated data. Comparing SetFit with Logistic Regression highlights the effectiveness of few-shot learning approaches, especially when high-quality, human-validated data is available.\n",
        "\n",
        "Further steps could involve:\n",
        "\n",
        "-   Expanding the human-annotated dataset in Argilla for potentially better SetFit performance.\n",
        "-   Experimenting with different LLMs for zero-shot classification and comparing their performance.\n",
        "-   Exploring different Sentence-transformers models and SetFit training configurations.\n",
        "-   Using Argilla's vector search capabilities to explore the dataset semantically.\n",
        "\n",
        "This approach provides a robust and adaptable framework for text classification tasks, especially in scenarios where labeled data is scarce or expensive to obtain."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/opt/miniconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
