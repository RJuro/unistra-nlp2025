{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Welcome to the Text Information Extraction Workshop! üéâ\n",
        "\n",
        "Hey there, future AI wranglers! In this workshop, we're going to dive into the exciting world of extracting structured information from text using the power of OpenAI's API. Think of it as teaching a robot to read news articles and pull out all the juicy details for us. ü§ñüì∞\n",
        "\n",
        "We'll cover everything from setting up your API connection to designing schemas that tell the AI *exactly* what kind of information we're after. Get ready to turn messy text into clean, organized data!\n",
        "\n",
        "## Setup: Let's Get Ready to Rumble üõ†Ô∏è\n",
        "\n",
        "First things first, we need to equip ourselves with the right tools. This involves installing the necessary Python library and importing modules. Think of it like gathering your spell components before casting a magical data extraction spell. ‚ú®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's import the ingredients for our AI recipe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata # for use in Google Colab\n",
        "import json # to handle JSON data\n",
        "from pydantic import BaseModel, Field # to define data schemas\n",
        "from typing import List, Optional, Dict # for type hints\n",
        "\n",
        "import textwrap # to make text output pretty\n",
        "\n",
        "# for use outside colab - if you're running this locally\n",
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv() # Load environment variables from .env file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What's happening here?**\n",
        "\n",
        "*   `openai`: This is the star of the show! The official OpenAI Python library that lets us talk to the models.\n",
        "*   `google.colab.userdata` (or `os`, `dotenv`):  We need to keep our API keys secret! `userdata` is for Google Colab secrets, while `os` and `dotenv` are for local development using environment variables (safer than hardcoding!).\n",
        "*   `json`:  AI models love to speak JSON. We'll use this to handle structured data in and out.\n",
        "*   `pydantic`:  This is our schema superhero! Pydantic helps us define exactly what kind of data we expect from the AI, ensuring it's in the format we want. Think of it as a blueprint for data.\n",
        "*   `typing`:  Just good coding practice to make our code readable and less error-prone.\n",
        "*   `textwrap`:  Because nobody likes walls of text. This will wrap our output nicely for easy reading.\n",
        "\n",
        "## Connecting to the AI Brain: OpenAI Client Setup üß†üîå\n",
        "\n",
        "Time to plug into the AI brain! We'll set up the OpenAI client using your API key.  We're using `userdata.get('TOGETHER_API_KEY')` (or `os.getenv('TOGETHER_API_KEY')`) to securely grab your API key. **Never hardcode your API keys!** Treat them like your Netflix password, but for powerful AI. ü§´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup OpenAI client with custom API key and base URL\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY') # for Google Colab user secrets\n",
        "# TOGETHER_API_KEY = os.getenv('TOGETHER_API_KEY') # for local environment variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's create the actual client that will do the talking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.together.xyz/v1\", # Using TogetherAI's API - you can change this\n",
        "    api_key=TOGETHER_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**\n",
        "\n",
        "*   We're creating an `OpenAI` client instance. This is our portal to the language models.\n",
        "*   `base_url`:  We're using TogetherAI's API endpoint here. You might use OpenAI's directly or another provider.\n",
        "*   `api_key`:  This authenticates us to use the API.  Keep it secret, keep it safe!\n",
        "\n",
        "## Summarizing Text: Baby Steps with AI üë∂üìù\n",
        "\n",
        "Let's start with something simple: summarizing text. We'll ask the AI to condense a French news article into a single, punchy English sentence.  Think of this as warming up before the main workout.\n",
        "\n",
        "Here's our French news article (`text_1`) discussing political reactions to the Ukraine war:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_1 = \"\"\"\n",
        "Vous pouvez partager un article en cliquant sur les ic√¥nes de partage en haut √† droite de celui-ci.\n",
        "La reproduction totale ou partielle d‚Äôun article, sans l‚Äôautorisation √©crite et pr√©alable du Monde, est strictement interdite.\n",
        "Pour plus d‚Äôinformations, consultez nos conditions g√©n√©rales de vente.\n",
        "Pour toute demande d‚Äôautorisation, contactez syndication@lemonde.fr.\n",
        "En tant qu‚Äôabonn√©, vous pouvez offrir jusqu‚Äô√† cinq articles par mois √† l‚Äôun de vos proches gr√¢ce √† la fonctionnalit√© ¬´ Offrir un article ¬ª.\n",
        "\n",
        "https://www.lemonde.fr/international/live/2025/03/03/en-direct-guerre-en-ukraine-pour-donald-trump-les-etats-unis-ont-des-problemes-plus-urgents-que-de-s-inquieter-de-poutine_6572748_3210.html\n",
        "\n",
        "L‚Äôaltercation entre Volodymyr Zelensky et Donald Trump a √©t√© d√©lib√©r√©ment provoqu√©e par les Etats-Unis, selon Friedrich Merz\n",
        "\n",
        "Lors d‚Äôune conf√©rence de presse, lundi, √† Hambourg, Friedrich Merz, le candidat de l‚Äôalliance CDU/CSU √† la chancellerie, a d√©clar√©, apr√®s des consultations avec les instances dirigeantes de la CDU √† Berlin, qu‚Äôil avait regard√© la sc√®ne de l‚Äôaltercation entre Volodymyr Zelensky et Donald Trump. ¬´¬†A mon avis, il ne s‚Äôagit pas d‚Äôune r√©action spontan√©e aux interventions de Zelensky, mais manifestement d‚Äôune escalade d√©lib√©r√©ment provoqu√©e lors de cette rencontre dans le bureau Ovale.¬†¬ª\n",
        "\n",
        "¬´¬†Il y a une certaine continuit√© dans ce que nous voyons actuellement de Washington dans la s√©rie d‚Äô√©v√©nements des derni√®res semaines et des derniers mois, y compris la pr√©sence de la d√©l√©gation am√©ricaine √† Munich √† la conf√©rence sur la s√©curit√©¬†¬ª, a-t-il poursuivi. ¬´¬†Je plaide pour que nous nous pr√©parions au fait que nous devrons faire beaucoup, beaucoup plus pour notre propre s√©curit√© dans les ann√©es et les d√©cennies √† venir¬†¬ª, a ajout√© le futur chancelier.\n",
        "\n",
        "N√©anmoins, il souhaite que ¬´¬†tout soit mis en ≈ìuvre afin de maintenir les Am√©ricains en Europe¬†¬ª, dans un contexte de sp√©culations selon lesquelles Trump pourrait retirer une partie des troupes am√©ricaines d‚ÄôAllemagne. Le futur chancelier a pr√©cis√© qu‚Äôil n‚Äôavait pas l‚Äôintention de se rendre aux Etats-Unis pour l‚Äôinstant et qu‚Äôil ne le ferait qu‚Äôapr√®s une √©ventuelle √©lection en tant que chancelier par le Bundestag.\n",
        "\n",
        "Par ailleurs, il a d√©fendu le chancelier Olaf Scholz (SPD) contre les critiques concernant son r√¥le lors du sommet des dirigeants occidentaux √† Londres. ¬´¬†Il n‚Äôest pas surprenant que l‚ÄôAllemagne ne soit pas pleinement per√ßue et prise au s√©rieux sur la sc√®ne internationale en ce moment, a-t-il d√©clar√©. Tout autre chancelier dans sa situation ‚Äì ayant perdu sa majorit√© parlementaire et √©tant en transition vers un nouveau gouvernement ‚Äì conna√Ætrait la m√™me difficult√©.¬†¬ª\n",
        "\n",
        "Il a soulign√© que lui et Olaf Scholz s‚Äôefforcent d‚Äô¬´¬†introduire la position allemande dans les n√©gociations internationales et europ√©ennes en √©troite coordination¬†¬ª. Toutefois, il estime qu‚Äôil ¬´¬†serait souhaitable que l‚ÄôAllemagne participe bient√¥t √† ces discussions avec un chef de gouvernement √©lu et disposant d‚Äôune majorit√© au Bundestag¬†¬ª.\n",
        "\n",
        "3/3 2025\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's call the language model to summarize this French text. We're using `meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo` ‚Äì a powerful model from Meta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the LLM to summarize the text\n",
        "chat_completion = client.chat.completions.create(\n",
        "    #model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\", # You can try a larger model for potentially better results\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\", # A good balance of speed and performance\n",
        "\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\", # System message sets the AI's persona\n",
        "            \"content\": \"You are a helpful assistant.\", # Simple instruction for general helpfulness\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\", # User message is our actual request\n",
        "            \"content\": \"Summarize the following French text in one sentence in English: \" + text_1 , # Our summarization task\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "output = chat_completion.choices[0].message.content # Extract the AI's response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now, let's make that summary readable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(textwrap.fill(output, width=80)) # Wrap the output for better readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What did we just do?**\n",
        "\n",
        "*   We used `client.chat.completions.create` to send a request to the language model.\n",
        "*   `model`: We specified which language model to use.\n",
        "*   `messages`:  This is the conversation history. We have a `system` message to set the AI's role and a `user` message with our summarization request.\n",
        "*   `chat_completion.choices[0].message.content`:  This digs into the API response to get the actual text summary from the AI.\n",
        "*   `textwrap.fill`:  Makes the summary look nice and not like a long, unbroken line.\n",
        "\n",
        "## Creating Structured Data: Meet Pydantic Schemas üèóÔ∏è\n",
        "\n",
        "Summarization is cool, but what if we want *structured* information?  This is where Pydantic and schemas come to the rescue!  Think of a schema as a mold. We define the shape we want our data to have, and Pydantic helps us ensure the AI output fits that mold perfectly.\n",
        "\n",
        "Let's start with a simple example: a `User` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the schema for the User object using Pydantic.\n",
        "class User(BaseModel):\n",
        "    name: str = Field(description=\"user name\") # Field with description for clarity\n",
        "    address: str = Field(description=\"address\") # Another field with description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Pydantic Power Explained:**\n",
        "\n",
        "*   `BaseModel`:  The foundation of our schema.  It tells Pydantic we're defining a data structure.\n",
        "*   `name: str = Field(...)`:  We're defining a field called `name` that *must* be a string (`str`).  `Field(...)` lets us add extra info, like `description`.\n",
        "*   `description`:  Super helpful for the AI!  It tells the model what each field is supposed to represent.\n",
        "\n",
        "Now, let's ask the AI to create a `User` object in JSON format, following our schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the LLM to create a User object in JSON format\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    response_format={\"type\": \"json_object\", \"schema\": User.model_json_schema()}, # Important! Tell API we want JSON output matching the schema\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant that answers in JSON.\", # System message - AI answers in JSON\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Create a user named Alice, who lives in 42, Wonderland Avenue. Output in JSON.\", # User request\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "created_user = json.loads(chat_completion.choices[0].message.content) # Parse JSON response\n",
        "print(json.dumps(created_user, indent=2)) # Print nicely formatted JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Improvements:**\n",
        "\n",
        "*   `response_format={\"type\": \"json_object\", \"schema\": User.model_json_schema()}`:  This is the magic! We're telling the OpenAI API: \"Hey, expect a JSON object back, and here's the schema it should follow (`User.model_json_schema()`)\". Pydantic automatically generates the JSON schema from our `User` class.\n",
        "*   `json.loads(...)`: We parse the JSON string response from the AI into a Python dictionary.\n",
        "*   `json.dumps(..., indent=2)`:  We print the JSON in a nicely formatted way, making it easy to read.\n",
        "\n",
        "## Extracting Article Details: Generalized Schema for News üì∞üîç\n",
        "\n",
        "Now for the main event: extracting information from news articles! We'll use a more complex, generalized schema called `ExtractScheme` designed to capture key details from various news articles.  This schema is our blueprint for extracting the *essence* of a news story."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExtractScheme(BaseModel):\n",
        "    title: str = Field(description=\"Title of the news article\")\n",
        "    publication_date: str = Field(description=\"Date when the article was published. If not explicitly mentioned, infer from article content if possible.\")\n",
        "    main_event: str = Field(description=\"Primary event or topic discussed in the article\")\n",
        "    event_summary: str = Field(description=\"A brief summary of the event or article's main points\")\n",
        "    entities_involved: List[str] = Field(description=\"Organizations, countries, or key entities involved in the event\")\n",
        "    key_people: List[str] = Field(description=\"Key people or figures mentioned in relation to the event\")\n",
        "    relevant_locations: Optional[List[str]] = Field(description=\"Locations that are central to the event, if any\")\n",
        "    key_developments: Optional[List[str]] = Field(description=\"Key developments or actions that have occurred or are expected\")\n",
        "    potential_impact: Optional[List[str]] = Field(description=\"Potential impacts or consequences of the event\")\n",
        "    keywords: List[str] = Field(description=\"Key terms or phrases that are central to the article\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**`ExtractScheme` Breakdown:**\n",
        "\n",
        "*   We've defined fields to capture the title, publication date, main event, summary, entities, people, locations, developments, impact, and keywords.  Basically, everything we want to know about a news article in a structured way.\n",
        "*   `List[str]`:  For fields like `entities_involved` and `key_people`, we expect a *list* of strings, as there can be multiple entities and people.\n",
        "*   `Optional[List[str]]`: `relevant_locations`, `key_developments`, and `potential_impact` are optional. Not all articles will have explicit locations or details for these.\n",
        "\n",
        "Let's use our French text (`text_1`) again and see how well the AI can extract information using this schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the LLM to extract information from text_1 using ExtractScheme\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    response_format={\"type\": \"json_object\", \"schema\": ExtractScheme.model_json_schema()}, # Enforce JSON output with ExtractScheme schema\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with extracting structured information from a news article. Follow the schema provided below to extract the relevant details. You do not invent information that is not in the provided text. Output in English JSON format.\", # Detailed system instruction\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Extract article information from the following French text and output in English JSON format: \" + text_1, # User request with text_1\n",
        "        },\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the extracted output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_output = json.loads(chat_completion.choices[0].message.content) # Parse JSON\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2)) # Print nicely, handle non-ASCII characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Inspecting the Schema:**\n",
        "\n",
        "You can check out the generated JSON schema to see exactly what we're sending to the API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ExtractScheme.model_json_schema() # Show the JSON schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or as a string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_schema = str(ExtractScheme.model_json_schema()) # Get schema as string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Schema in Prompt (Alternative Method):**\n",
        "\n",
        "Instead of `response_format`, you can also directly include the JSON schema in the user prompt.  This can be useful for debugging or more direct control.  Let's try it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the LLM to extract information from text_1 using schema string in prompt\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    #response_format={\"type\": \"json_object\", \"schema\": CaseDetails.model_json_schema()}, # alternative method - we are not using CaseDetails here, it's a typo in the original notebook\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with extracting structured information from a news article. Follow the schema provided below to extract the relevant details. You do not invent information that is not in the provided text. You output JSON only in English. Nothing else.\", # Strict system message\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Extract article information from the following French text and output in English JSON format: \" + text_1 + \" Use following JSON schema:\" + json_schema, # User prompt with text and schema string\n",
        "        },\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And print the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_output = json.loads(chat_completion.choices[0].message.content)\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both `response_format` and including the schema in the prompt achieve the same goal ‚Äì guiding the AI to produce structured JSON output according to our `ExtractScheme`.\n",
        "\n",
        "## Second Example: Tech News Time! üöÄüì±\n",
        "\n",
        "Let's test our `ExtractScheme` on a different type of news article ‚Äì tech news! Here's an English article (`text_2`) about Meta's AI chatbot app launch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_2 = \"\"\"\n",
        "Meta‚Äôs AI chatbot will soon have a standalone app\n",
        "‚Äã\n",
        " Summarise\n",
        "‚Äã\n",
        "Emma RothFeb 28, 2025 at 12:05 AM GMT+1\n",
        "STK043_VRG_Illo_N_Barclay_6_Meta\n",
        "Meta is planning to launch a dedicated app for its AI chatbot, according to a report from CNBC. The Verge can also confirm that Meta is working on the standalone app. The new app could launch in the second quarter of this year, CNBC says, joining the growing number of standalone AI apps, including OpenAI‚Äôs ChatGPT, Google Gemini, and Microsoft Copilot.\n",
        "\n",
        "Meta has already brought its AI chatbot across Facebook, Instagram, Messenger, and WhatsApp, but launching a standalone app could help the company reach people who don‚Äôt already use those platforms. Similar to rival chatbots, Meta AI can answer questions, generate images, edit photos, and more. It recently gained the ability to use its ‚Äúmemory‚Äù to provide better recommendations.\n",
        "\n",
        "In a response to CNBC‚Äôs report, OpenAI CEO Sam Altman joked, ‚Äúok fine maybe we‚Äôll do a social app.‚Äù Meta declined to comment.\n",
        "\n",
        "Meta has ramped up its efforts to compete in the AI industry in recent months, with CEO Mark Zuckerberg announcing plans to invest up to $65 billion to further the company‚Äôs AI ambitions. The company also plans on holding an event dedicated to AI on April 29th.\n",
        "\n",
        "Additional reporting by Alex Heath.\n",
        "\n",
        "5 Comments5 New\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the same `ExtractScheme` and prompt structure.  This time, we'll also add an `assistant` example message.  This is like showing the AI a \"good example\" of the JSON output we expect, based on the *first* text example (`text_1`).  Example messages can significantly improve the accuracy and format of the AI's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the LLM to extract information from text_2 using ExtractScheme and example assistant message\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    #response_format={\"type\": \"json_object\", \"schema\": CaseDetails.model_json_schema()}, # Typo again - ignore CaseDetails\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with extracting structured information from a news article. Follow the schema provided below to extract the relevant details. You do not invent information that is not in the provided text. You output JSON only in English. Nothing else.\", # System message\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Extract article information from the following text and output in English JSON format: \" + text_2 + \" Use following JSON schema:\" + json_schema, # User request with text_2 and schema\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\", # Assistant message - example of desired output format\n",
        "            \"content\": \"\"\"{\n",
        "  \"title\": \"L‚Äôaltercation entre Volodymyr Zelensky et Donald Trump a √©t√© d√©lib√©r√©ment provoqu√©e par les Etats-Unis, selon Friedrich Merz\",\n",
        "  \"publication_date\": \"March 3, 2025\",\n",
        "  \"main_event\": \"Political reactions to an altercation between Volodymyr Zelensky and Donald Trump\",\n",
        "  \"event_summary\": \"Friedrich Merz claims that the altercation between Zelensky and Trump was deliberately provoked by the U.S. and expresses concerns about US commitment to European security.\",\n",
        "  \"entities_involved\": [\n",
        "    \"United States\",\n",
        "    \"Ukraine\",\n",
        "    \"Germany\",\n",
        "    \"CDU/CSU alliance\"\n",
        "  ],\n",
        "  \"key_people\": [\n",
        "    \"Friedrich Merz\",\n",
        "    \"Volodymyr Zelensky\",\n",
        "    \"Donald Trump\",\n",
        "    \"Olaf Scholz\"\n",
        "  ],\n",
        "  \"relevant_locations\": [\n",
        "    \"Hambourg\",\n",
        "    \"Berlin\",\n",
        "    \"Munich\",\n",
        "    \"Washington\",\n",
        "    \"London\"\n",
        "  ],\n",
        "  \"key_developments\": [\n",
        "    \"Friedrich Merz's press conference in Hambourg\",\n",
        "    \"Consultations with CDU leadership in Berlin\",\n",
        "    \"Merz's statement on US-Europe relations and German security\",\n",
        "    \"Defense of Olaf Scholz's role at a summit in London\"\n",
        "  ],\n",
        "  \"potential_impact\": [\n",
        "    \"Potential shift in US foreign policy under Trump\",\n",
        "    \"Increased pressure on Europe to ensure its own security\",\n",
        "    \"Speculation about US troop withdrawal from Germany\",\n",
        "    \"Impact on German political landscape and leadership\"\n",
        "  ],\n",
        "  \"keywords\": [\n",
        "    \"Ukraine\",\n",
        "    \"Donald Trump\",\n",
        "    \"Volodymyr Zelensky\",\n",
        "    \"Friedrich Merz\",\n",
        "    \"US foreign policy\",\n",
        "    \"European security\",\n",
        "    \"German politics\"\n",
        "  ]\n",
        "}\"\"\", # Example JSON based on text_1\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\", # Another user message - this is a repetition from the original notebook, probably unintentional but kept for consistency\n",
        "            \"content\": \"Extract article information from the following text and output in English JSON format: \" + text_2 + \" Use following JSON schema:\" + json_schema, # User request with text_2 and schema again\n",
        "        },\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the extracted JSON for the tech news article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_output = json.loads(chat_completion.choices[0].message.content)\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch Processing: Extracting Data from Many Articles üöÄÊâπÈáèÂ§ÑÁêÜ\n",
        "\n",
        "Now, let's scale things up!  What if we have a whole bunch of news articles we want to process?  We can use a loop to iterate through articles, extract information for each, and then organize the results into a table (Pandas DataFrame) for easy analysis.\n",
        "\n",
        "First, we'll load articles from a local JSONL file (`paraphrased_articles.jsonl`).  JSONL is a convenient format for storing multiple JSON objects, one per line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os # already imported, but included for clarity in this section\n",
        "import json # already imported\n",
        "from typing import List, Optional # already imported\n",
        "from pydantic import BaseModel, Field # already imported\n",
        "from openai import OpenAI # already imported\n",
        "\n",
        "# Define the extraction schema (same as before)\n",
        "class ExtractScheme(BaseModel):\n",
        "    #title: str = Field(description=\"Title of the news article\") # Removed from schema in this version\n",
        "    #publication_date: str = Field(description=\"Date when the article was published. If not explicitly mentioned, infer from article content if possible.\") # Removed from schema\n",
        "    real_article: str = Field(description=\"Real article or scraping problem/artifact/copyright issue? - Select YES/NO only.\") # Added field - article validity check\n",
        "    main_event: str = Field(description=\"Primary event or topic discussed in the article\")\n",
        "    event_summary: str = Field(description=\"A brief summary of the event or article's main points\")\n",
        "    entities_involved: List[str] = Field(description=\"Organizations, countries, or key entities involved in the event\")\n",
        "    key_people: List[str] = Field(description=\"Key people or figures mentioned in relation to the event\")\n",
        "    relevant_locations: Optional[List[str]] = Field(description=\"Locations that are central to the event, if any\")\n",
        "    key_developments: Optional[List[str]] = Field(description=\"Key developments or actions that have occurred or are expected\")\n",
        "    potential_impact: Optional[List[str]] = Field(description=\"Potential impacts or consequences of the event\")\n",
        "    keywords: List[str] = Field(description=\"Key terms or phrases that are central to the article\")\n",
        "\n",
        "# Setup OpenAI client (same as before)\n",
        "TOGETHER_API_KEY = os.getenv('TOGETHER_API_KEY') # Ensure API key is set in environment if running locally\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.together.xyz/v1\",\n",
        "    api_key=TOGETHER_API_KEY\n",
        ")\n",
        "\n",
        "# Load articles from local jsonl file\n",
        "def load_articles_from_jsonl(file_path):\n",
        "    articles = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f: # Open file for reading\n",
        "        for line in f: # Read line by line\n",
        "            article_json = json.loads(line.strip()) # Parse each line as JSON\n",
        "            articles.append(article_json) # Add to article list\n",
        "    return articles\n",
        "\n",
        "# Path to your local jsonl file - replace with your actual path!\n",
        "jsonl_file_path = 'paraphrased_articles.jsonl' # Replace with your actual file path\n",
        "articles_data = load_articles_from_jsonl(jsonl_file_path) # Load articles\n",
        "\n",
        "# Filter articles - ensure we have text and it's long enough\n",
        "filtered_articles_data = []\n",
        "for article in articles_data:\n",
        "    if 'text' in article and isinstance(article['text'], str) and len(article['text']) >= 100: # Check for text and minimum length\n",
        "        filtered_articles_data.append(article) # Add to filtered list\n",
        "\n",
        "articles_data = filtered_articles_data # Replace original with filtered data\n",
        "print(f\"Number of articles after filtering: {len(articles_data)}\") # Print number of articles after filtering\n",
        "\n",
        "extracted_data_table = [] # Initialize list to store extracted data\n",
        "json_schema = str(ExtractScheme.model_json_schema()) # Get JSON schema string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Schema Modification:**\n",
        "\n",
        "Notice we've slightly modified the `ExtractScheme` in this batch processing section:\n",
        "\n",
        "*   `title` and `publication_date` fields are *removed*. This might be because these are already available in the input `articles_data`.\n",
        "*   `real_article: str = Field(...)`: A new field `real_article` is added to check if the text is a genuine article or some kind of scraping artifact. This is a practical addition for real-world data processing, where data can be messy.\n",
        "\n",
        "**Batch Processing Loop:**\n",
        "\n",
        "Now for the loop that processes each article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary additional libraries - pandas and tqdm\n",
        "import pandas as pd # for DataFrames\n",
        "from tqdm.notebook import tqdm # for progress bars in notebooks\n",
        "\n",
        "# Iterate over articles and perform extraction with tqdm progress bar\n",
        "for article in tqdm(articles_data[:10], desc=\"Processing Articles\"): # Limiting to first 10 articles for demonstration, tqdm for progress bar\n",
        "    article_text = article['text'] # Extract article text\n",
        "    original_title = article['title'] # Extract original title\n",
        "    original_date = article['date'] # Extract original date\n",
        "\n",
        "    try: # Error handling - in case extraction fails for an article\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\", # Using a larger model here - 70B version\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an AI model tasked with extracting structured information from a news article. Follow the schema provided below to extract the relevant details. You do not invent information that is not in the provided text. You output JSON only in English. Nothing else.\", # System message\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Extract article information from the following text and output in English JSON format: {article_text} Use following JSON schema:\" + json_schema, # User message with article text and schema\n",
        "                },\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\", \"schema\": ExtractScheme.model_json_schema()}, # Enforce JSON and schema\n",
        "        )\n",
        "\n",
        "        extracted_content_json = json.loads(chat_completion.choices[0].message.content) # Parse JSON response\n",
        "        extracted_content = ExtractScheme(**extracted_content_json).dict() # Validate against schema and convert to dict\n",
        "\n",
        "        # Add original title and date to the extracted data for the table\n",
        "        extracted_content['original_title'] = original_title # Add original title to extracted data\n",
        "        extracted_content['original_date'] = original_date # Add original date to extracted data\n",
        "        extracted_data_table.append(extracted_content) # Append extracted data to table list\n",
        "\n",
        "        print(f\"Extracted information for: {original_title}\") # Print success message\n",
        "\n",
        "    except Exception as e: # Catch any errors during processing\n",
        "        print(f\"Error processing article: {original_title}. Error: {e}\") # Print error message\n",
        "        extracted_data_table.append({'original_title': original_title, 'original_date': original_date, 'error': str(e)}) # Store error info\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(extracted_data_table) # Create DataFrame from extracted data\n",
        "\n",
        "# Flatten list columns - make the DataFrame easier to view\n",
        "def flatten_list_columns(df):\n",
        "    flattened_df = df.copy() # Create a copy to avoid modifying original DataFrame\n",
        "    list_columns = [col for col in df.columns if df[col].apply(lambda x: isinstance(x, list)).any()] # Identify list columns\n",
        "\n",
        "    for col in list_columns:\n",
        "        # Convert lists to comma-separated strings\n",
        "        flattened_df[col] = flattened_df[col].apply(\n",
        "            lambda x: ', '.join(x) if isinstance(x, list) and x else '') # Join list elements with commas, handle empty lists\n",
        "\n",
        "    return flattened_df\n",
        "\n",
        "# Flatten the dataframe and display the head\n",
        "flattened_df = flatten_list_columns(df) # Flatten DataFrame\n",
        "print(\"\\nExtracted Data Table (Flattened):\") # Print header\n",
        "display(flattened_df.head()) # Display first few rows of flattened DataFrame\n",
        "\n",
        "# Optional: Save to CSV - uncomment to save results to a CSV file\n",
        "flattened_df.to_csv('extracted_news_data_flattened.csv', index=False) # Save to CSV\n",
        "\n",
        "# Original output format (JSON) - for inspection of original structure\n",
        "print(\"\\nExtracted Data Table (Original):\") # Print header\n",
        "for row in extracted_data_table: # Iterate through extracted data\n",
        "    print(json.dumps(row, ensure_ascii=False, indent=2)) # Print each row as formatted JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Batch Processing Highlights:**\n",
        "\n",
        "*   `for article in tqdm(articles_data[:10], desc=\"Processing Articles\"):`: We loop through the *first 10 articles* (`[:10]`) for demonstration purposes. `tqdm` adds a progress bar, which is super useful when processing many articles.\n",
        "*   `try...except`:  Error handling!  If something goes wrong during extraction for a particular article, the loop continues processing other articles, and we log the error.\n",
        "*   `pd.DataFrame(extracted_data_table)`:  We convert the list of extracted dictionaries into a Pandas DataFrame. DataFrames are amazing for tabular data manipulation and analysis.\n",
        "*   `flatten_list_columns(df)`:  This function flattens columns that contain lists into comma-separated strings. This makes the DataFrame easier to read and export to CSV.\n",
        "*   `flattened_df.to_csv('extracted_news_data_flattened.csv', index=False)`:  Optionally, we save the DataFrame to a CSV file.  CSV is a widely compatible format for data sharing and analysis in tools like Excel or other data analysis software.\n",
        "*   `print(json.dumps(row, ensure_ascii=False, indent=2))`:  We also print the original JSON output for each article, in case you want to see the un-flattened, structured JSON data.\n",
        "\n",
        "## Conclusion: You're an AI Data Extraction Wizard! üßô‚Äç‚ôÇÔ∏è‚ú®\n",
        "\n",
        "Congratulations! You've made it through the workshop and learned how to:\n",
        "\n",
        "*   Connect to OpenAI's API (or a compatible alternative like TogetherAI).\n",
        "*   Define data schemas using Pydantic to structure AI outputs.\n",
        "*   Extract information from text, from simple summaries to complex structured data.\n",
        "*   Process multiple articles in batch and organize the results into a table.\n",
        "\n",
        "You're now equipped to build your own AI-powered information extraction tools!  Think of the possibilities: analyzing news trends, extracting product details from descriptions, processing customer feedback, and much more.  The text data world is your oyster! ü¶™üåç\n",
        "\n",
        "Keep experimenting, keep building, and have fun turning text into data! üéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/opt/miniconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
